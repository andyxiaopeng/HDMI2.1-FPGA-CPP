## 1618编解码时延测试实验

### 为何需要测试

在实际的工作场景中，hdmi4个通道，每个通道的最大速度为12G/s，而gt收发器保证了数据的串行发送，其串行的数据包大小可以选择40、64等。以40bit数据大小来算，12/40 = 300M ，也就是说编码器的频率最少需要达到300M以上才能保证gt收发器正常、无误的运行。如果选择64bit的串行数据包，12/64 = 187.5M ，也就是说编码器的频率最少需要达到188M以上才能保证gt收发器正常、无误的运行。此外，这是极限的时钟频率，在考虑到工业应用环境，这个时钟频率还需要提升到更大，必须具有一定的冗余，并且由于编码器的特殊性，其内部需要9b编码器和7b编码器的顺序执行才能保证正确计算RD值，也能更好的保证编码效果，所以编码器内部时钟需要外部时钟的2倍频率。

### 代码实现

300M频率就是说，每秒有300M个周期，每毫秒有300k个周期，每微秒有300个周期、每纳秒有0.3个周期。考虑实际工业环境，编码器内部需要达到每纳秒0.7个周期（翻倍+冗余）才可以，综上1.43ns为一个周期。

187.5M频率，每秒有187.5M个周期，每毫秒187.5k个周期，每微秒187.5个周期，每纳秒0.1875个周期。考虑实际工业环境，编码器内部需要达到每纳秒0.375个周期（翻倍+冗余）才可以，综上2.67ns为一个周期。

#### 实验1

设置gt收发器数据宽度为40bit的验证。12/40 = 300M，翻倍+冗余 700M

设置仿真时间为ns，时间精度为ps，设置时间翻转为0.75，也就是，0.75ns翻转一次电频信号，合计1.5个纳秒为一个周期。**测试通过，编码和解码能顺利接收到相同数据**

#### 实验2

设置gt收发器数据宽度为64bit的验证。12/64 = 187.5M， 翻倍 375M

设置仿真时间为ns，时间精度为ps，设置时间翻转为1.335，也就是，1.335ns翻转一次电频信号，合计2.67个纳秒为一个周期。**测试通过，编码和解码能顺利接收到相同数据**